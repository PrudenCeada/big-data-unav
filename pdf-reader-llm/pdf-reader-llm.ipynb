{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760cfa91-b04f-4cdf-b473-461641a6ced4",
   "metadata": {},
   "source": [
    "### **DELIVERABLE 2 - TRD**\n",
    "\n",
    "The goal of this deliverable was to design and implement a system that allows **extracting key information** from pharmacological scientific studies in PDF format and presenting it in a structured format such as a table, using queries to an LLM. The variables of interest considered were:\n",
    "\n",
    "- **Title**\n",
    "- **Authors**\n",
    "- **Publication Date**\n",
    "- **Objective of the Study**\n",
    "- **Methodology Used**\n",
    "- **Study Sample**\n",
    "- **Results**\n",
    "- **Conclusions**\n",
    "- **Clinical Relevance**\n",
    "\n",
    "The development of the script was an iterative process, marked by several technical difficulties, adjustments, and important decisions. This notebook documents **the entire process**, from the initial attempts to the final solution, explaining each stage.\n",
    "\n",
    "The extraction process was carried out in two phases, initially attempting to use the **Hugging Face API**, and ultimately switching to the **OpenAI API**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1c231-98a6-4566-8965-515ea60bb41d",
   "metadata": {},
   "source": [
    "### **First Phase: Attempt with Hugging Face Models**\n",
    "\n",
    "#### **Initial Implementation**\n",
    "Initially, I decided to use LLM models available on the Hugging Face platform, such as:\n",
    "\n",
    "- `bert-base-uncased`\n",
    "- `deepset/roberta-base-squad2`\n",
    "- `bigscience/bloomz-7b1`\n",
    "- `mistralai/Mistral-7B-Instruct`\n",
    "\n",
    "**Reason**: These models can be executed through the Hugging Face API, allowing direct inferences.\n",
    "\n",
    "#### **Problems Encountered**\n",
    "1. **503 Errors (Service Unavailable):** Most models returned availability errors.\n",
    "2. **Excess of Tokens:** Many PDFs had extensive content that exceeded the model's context limits.\n",
    "3. **Imprecise Answers:** The model responses were not concise or structured.\n",
    "\n",
    "**Conclusion**: The Hugging Face models were not a viable solution due to these limitations. Next, I opted to switch to the **OpenAI API**, which offers greater robustness and processing capacity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ae796-a0a6-4441-92e1-68be3aab2604",
   "metadata": {},
   "source": [
    "### **Segunda fase: Uso de la API de OpenAI**\n",
    "\n",
    "#### **Configuración de la API de OpenAI**\n",
    "Inicialmente, me encontré con problemas al utilizar la última versión de `openai`. La sintaxis para `ChatCompletion` había cambiado, lo que generaba errores.\n",
    "\n",
    "**Solución**: Instalé una versión anterior de la librería que garantizaba el funcionamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6239128",
   "metadata": {},
   "source": [
    "### **Second Phase: Using the OpenAI API**\n",
    "\n",
    "#### **Configuring the OpenAI API**\n",
    "Initially, I encountered issues when using the latest version of `openai`. The syntax for `ChatCompletion` had changed, which generated errors.\n",
    "\n",
    "**Solution**: I installed an older version of the library to ensure functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2daa5208-f81e-460f-b795-a78d84078941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from openai==0.28) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.9.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pruden\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba0843-b6a5-403c-b395-be2050bf3740",
   "metadata": {},
   "source": [
    "### **Configuring Libraries and OpenAI API Key**\n",
    "\n",
    "#### **Description**\n",
    "This initial code snippet configures the necessary libraries and defines the API key to interact with **OpenAI**. Special emphasis is placed on **hiding** the API key using environment variables, a recommended practice to protect sensitive information.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Initial Problem**\n",
    "- In the early versions of the code, the API key was written directly in the script, which poses a **security risk** if the code is shared publicly or uploaded to platforms like **GitHub**.\n",
    "- It is important to handle API keys securely to prevent misuse.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Decision Made**\n",
    "1. **Use of Environment Variables**:\n",
    "   - Instead of writing the key directly in the script, it is stored in an environment variable (`Documents_OpenAI`).\n",
    "   - This variable is accessed using the `os` library with `os.getenv()`.\n",
    "\n",
    "2. **Benefit**:\n",
    "   - Protects the API key by not exposing it directly in the code.\n",
    "   - Facilitates key management in different environments (development, production, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b6b4f7fb-9d31-4be4-ac73-7d0c9f997048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # Para interactuar con la API de OpenAI\n",
    "import pdfplumber  # Para leer y extraer texto de PDFs\n",
    "import pandas as pd  # Para estructurar y manipular datos\n",
    "import os # Para manejar variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6f7f88dd-20ec-46a1-b1ef-88f7be3c0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuro la clave API de OpenAI desde variables de entorno para no exponer directamente la clave\n",
    "openai.api_key = os.getenv(\"Documents_OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "374f46d0-3770-4fa0-96f7-47a725d490d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de interés a extraer\n",
    "variables_of_interest = [\n",
    "    \"Title\",\n",
    "    \"Authors\",\n",
    "    \"Publication Date\",\n",
    "    \"Objective of the Study\",\n",
    "    \"Methodology Used\",\n",
    "    \"Study Sample\",\n",
    "    \"Results\",\n",
    "    \"Conclusions\",\n",
    "    \"Clinical Relevance\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c1ce2-8ae9-4f95-9c0b-7e5a2fe68519",
   "metadata": {},
   "source": [
    "### **Decisions Made to Handle Token Overflow**\n",
    "\n",
    "#### **Initial Problem**\n",
    "Once I started testing with the OpenAI API, I encountered a recurring problem when working with long texts extracted from PDFs. OpenAI has a limitation on the number of tokens that can be sent in each query to its models (for example, `gpt-3.5-turbo` allows a maximum of 4096 tokens per request). When I tried to send complete documents or extensive texts as context, the API returned errors like:\n",
    "\n",
    "> `This model's maximum context length is 4096 tokens. However, your messages resulted in [X] tokens.`\n",
    "\n",
    "This problem not only interrupted the flow of the analysis but also forced me to stop processing large documents or manually split the content, which was inefficient and impractical.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Decision Made**\n",
    "To solve this problem, I implemented a solution that automates the division of long texts into smaller fragments, ensuring that each fragment did not exceed the token limit allowed by the model. This was achieved with a function that:\n",
    "1. Splits the text into words.\n",
    "2. Creates controlled-length fragments that can be sent to the API independently.\n",
    "3. Assembles the responses from these fragments, when necessary, to build the final response.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Reasoning**\n",
    "1. **Avoid Token Errors:** Sending small fragments allows working within the model's limits and ensures that all texts can be processed, even the most extensive ones.\n",
    "2. **Maintain Efficiency:** This automatic division eliminates the need for manual interventions, speeding up the processing of PDFs.\n",
    "3. **Flexibility:** Adjusting the maximum size of the fragments (`max_tokens`) allows optimizing the balance between context and response according to the needs of the analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Result**\n",
    "With this strategy, the problems related to token overflow were solved. Now I can process complete PDFs, even those with a large amount of text, without errors or loss of information. This approach also allowed me to maintain the scalability of the project, making it possible to process multiple documents automatically.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Lesson Learned**\n",
    "Token limits are an important constraint when working with LLMs. Identifying this problem and making decisions aimed at fragmenting the texts was key to continuing the development of the project without interruptions. This experience highlighted the importance of adjusting queries to the technical constraints of the model used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c05480bb-5e9d-43a0-a2f4-252006dc356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, max_tokens=500):  # Reducido a fragmentos más pequeños\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        current_length += len(word) + 1  # Considera espacios\n",
    "        if current_length > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = len(word) + 1\n",
    "        current_chunk.append(word)\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0553b3-4d50-4cc4-bf71-37309faf6dbd",
   "metadata": {},
   "source": [
    "### **Adjustments in Queries for Direct Answers and Handling Rate Limit Errors**\n",
    "\n",
    "#### **Initial Problem**\n",
    "During development, I faced several challenges related to interacting with the OpenAI API:\n",
    "1. **Too Long Responses:** Initially, the queries returned lengthy responses with unnecessary introductions. For example, when asking for the title, the response included phrases like *\"The title of the study is...\"*, making the responses redundant for the purpose of the table.\n",
    "2. **Rate Limit Errors:** The API quickly reached the token limits per minute, especially when processing multiple PDFs sequentially. This resulted in frequent interruptions and required manually retrying failed queries.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Decisions Made**\n",
    "1. **Optimization of Questions**:\n",
    "   - For direct variables like *Title*, *Authors*, and *Publication Date*, specific questions were formulated with clear instructions to make the responses concise:\n",
    "     - *Title:* \"Provide only the title.\"\n",
    "     - *Authors:* \"List the names only.\"\n",
    "     - *Date:* \"Please answer only DD-MM-YYYY.\"\n",
    "   - For the other variables, a brief summary was requested using the instruction: *\"Please summarize the response briefly.\"*\n",
    "\n",
    "2. **Automatic Management of Rate Limit Errors**:\n",
    "   - Exception handling was implemented for rate limit errors (`RateLimitError`).\n",
    "   - The function automatically retries the query after a brief pause, eliminating the need for manual intervention.\n",
    "\n",
    "3. **Limits on Response Length**:\n",
    "   - The `max_tokens=100` parameter was configured to limit the length of responses, reducing unnecessary token usage and keeping the responses in the desired format.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Result**\n",
    "With these adjustments, the responses are now precise and aligned with the project's needs. Additionally, the function runs robustly, automatically handling rate limit errors and reducing the time lost in interruptions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Lesson Learned**\n",
    "Optimizing the questions asked and setting limits on the length of responses was key to avoiding redundancies and keeping the project efficient. Moreover, implementing a retry strategy for rate limit errors significantly improved the reliability of the code when processing large volumes of data.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6125841c-19b1-4ad3-851c-ba44adf08076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para consultar la API de OpenAI con respuestas directas para ciertas variables\n",
    "def query_openai_api_with_rate_limit(context, question, var):\n",
    "    try:\n",
    "        if var == \"Title\":\n",
    "            question = \"What is the title of the study? Provide only the title.\"\n",
    "        elif var == \"Authors\":\n",
    "            question = \"Who are the authors of the study? List the names only.\"\n",
    "        elif var == \"Publication Date\":\n",
    "            question = \"What is the publication date? Please answer only DD-MM-YYYY.\"\n",
    "        else:\n",
    "            question = f\"What is the {var}? Please summarize the response briefly.\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in pharmacology and healthcare. Provide concise and accurate answers to pharmaceutical-related questions.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {context}\\nQuestion: {question}\"}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            max_tokens=100,\n",
    "            temperature=0.2\n",
    "        )\n",
    "\n",
    "        answer = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return answer\n",
    "    except openai.error.RateLimitError as e:\n",
    "        print(f\"Rate limit reached: {e}. Retrying after a short delay.\")\n",
    "        time.sleep(1)\n",
    "        return query_openai_api_with_rate_limit(context, question, var)  # Reintenta la consulta\n",
    "    except openai.error.OpenAIError as e:\n",
    "        print(f\"Error al consultar la API de OpenAI: {e}\")\n",
    "        return None  # Devuelve None si hay un error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcba2a7-6692-4dbf-9b26-5f7fce262204",
   "metadata": {},
   "source": [
    "### **Text Extraction from PDF Files**\n",
    "\n",
    "#### **Context**\n",
    "To analyze documents in PDF format using language models like OpenAI GPT, the first step is to extract the full text from each file. However, at the beginning of development, I encountered several challenges related to text extraction:\n",
    "1. **Quality of Extracted Content:** Depending on how the PDF is structured (for example, if it includes images or scanned text), the extraction could fail or return incomplete content.\n",
    "2. **Unexpected Errors:** Some PDFs produced errors during reading, which interrupted the processing flow.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Decision Made**\n",
    "I implemented a dedicated function (`extract_text_from_pdf`) that uses the `pdfplumber` library to read PDFs and extract text. The function:\n",
    "1. Reads all pages of the document.\n",
    "2. Verifies if each page contains text before including it in the result.\n",
    "3. Handles exceptions, logging specific errors without interrupting the processing of other documents.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Code Details**\n",
    "- **Parameters**:\n",
    "  - `pdf_path`: Path to the PDF file to be processed.\n",
    "- **Return**:\n",
    "  - Concatenated text from all pages, or an empty string (`\"\"`) if an error occurs.\n",
    "- **Error Handling**:\n",
    "  - If the file cannot be read (for example, corrupt format), a message indicating the error is printed, and an empty string is returned.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4e6ec648-4ca0-40df-a578-34f1a9131118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función: extract_text_from_pdf\n",
    "# Esta función lee un PDF y extrae el texto completo de todas sus páginas.\n",
    "# Parámetros:\n",
    "# - pdf_path: Ruta al archivo PDF.\n",
    "# Retorna:\n",
    "# - Texto extraído del PDF.\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \" \".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6d1c7-4750-477c-93d9-65d39a1f4426",
   "metadata": {},
   "source": [
    "### **Information Extraction Process from PDFs: `process_pdfs`**\n",
    "\n",
    "#### **Context**\n",
    "The purpose of this function is to process a list of PDFs and extract key information defined by the **variables of interest**. This includes aspects such as title, authors, publication date, methodology, among others. Initially, I encountered several challenges when processing multiple documents:\n",
    "1. **Lack of Extractable Text:** Some PDFs did not contain legible text, which generated errors or empty results.\n",
    "2. **Repetitive or Unnecessary Responses:** When splitting long texts into fragments, the responses could include redundancies if the processing was not limited.\n",
    "3. **PDF Identification:** It was difficult to track which document the results belonged to, especially when handling large volumes of data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Decisions Made**\n",
    "1. **Handling PDFs Without Text**:\n",
    "   - For PDFs without legible text, the function adds a record with `None` values for all variables and the PDF name, ensuring that no document is omitted in the final result.\n",
    "\n",
    "2. **Splitting into Fragments**:\n",
    "   - The function splits the full text of each PDF into manageable fragments using the `split_text_into_chunks` function, ensuring that the queries do not exceed the token limits of the OpenAI model.\n",
    "\n",
    "3. **Optimization of Responses**:\n",
    "   - Once a valid response for a variable is obtained from a fragment, the processing of subsequent fragments for that variable stops, reducing the time and cost of queries.\n",
    "\n",
    "4. **Document Identification**:\n",
    "   - The PDF file name is added as an additional key (`PDF Name`) in each record of the table, allowing tracking of the source of the extracted data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bb2e423a-9f1a-4b94-b750-0f1a7f76682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función: process_pdfs\n",
    "# Procesa múltiples PDFs para extraer información de cada uno de ellos.\n",
    "# Parámetros:\n",
    "# - pdf_paths: Lista de rutas a los PDFs.\n",
    "# Retorna:\n",
    "# - Lista de diccionarios donde cada diccionario representa un documento y sus variables extraídas.\n",
    "def process_pdfs(pdf_paths):\n",
    "    data = []\n",
    "    for pdf_path in pdf_paths:\n",
    "        print(f\"Procesando {pdf_path}...\")\n",
    "        document_text = extract_text_from_pdf(pdf_path)\n",
    "        if not document_text:\n",
    "            data.append({\"PDF Name\": os.path.basename(pdf_path), **{var: None for var in variables_of_interest}})\n",
    "            continue\n",
    "        chunks = split_text_into_chunks(document_text)\n",
    "        row = {\"PDF Name\": os.path.basename(pdf_path)}\n",
    "        for var in variables_of_interest:\n",
    "            answers = []\n",
    "            for chunk in chunks:\n",
    "                if answers:\n",
    "                    break  # Si ya hay respuesta, no procesar más fragmentos\n",
    "                answer = query_openai_api_with_rate_limit(chunk, f\"What is the {var}?\", var)\n",
    "                if answer:\n",
    "                    answers.append(answer)\n",
    "            row[var] = answers[0] if answers else None\n",
    "            print(f\"Variable: {var}, Respuesta: {row.get(var)}\")\n",
    "        data.append(row)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "16efe8f1-aa19-4c11-b812-27e3d1784298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de rutas a los PDFs que se procesarán.\n",
    "# Asegúrate de que estos archivos existan en el directorio de trabajo.\n",
    "pdf_paths = [\n",
    "    \"fpsyg-08-00308.pdf\",\n",
    "    \"fpsyg-09-01240.pdf\",\n",
    "    \"fpsyg-11-01354.pdf\",\n",
    "    \"fpsyg-12-639236.pdf\",\n",
    "    \"fpsyt-14-1301143.pdf\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca12ea9-9b74-4229-9994-5e411dfcee1f",
   "metadata": {},
   "source": [
    "After reading and processing the PDFs, we finally managed to generate the desired files containing the extracted and organized information. To optimize result management and avoid overwriting, we implemented the `datetime` module, as shown in the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "54bc9d61-0afc-4e7d-af20-fad5783626aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando fpsyg-08-00308.pdf...\n",
      "Variable: Title, Respuesta: Placebo and Nocebo Effects: The Advantage of Measuring Expectations and Psychological Factors\n",
      "Variable: Authors, Respuesta: Nicole Corsi and Luana Colloca.\n",
      "Variable: Publication Date, Respuesta: 06-03-2017\n",
      "Variable: Objective of the Study, Respuesta: The objective of the study was to highlight the importance of measuring expectations and psychological factors in understanding and harnessing the placebo and nocebo effects in healthcare and pharmacology.\n",
      "Variable: Methodology Used, Respuesta: The methodology used in the study involved measuring expectations and psychological factors related to placebo and nocebo effects. Researchers likely conducted experiments or surveys to assess participants' beliefs, attitudes, and psychological states in relation to the study's objectives.\n",
      "Variable: Study Sample, Respuesta: The study sample in the research consisted of individuals who were exposed to placebo and nocebo effects. The researchers measured expectations and psychological factors in these individuals to understand the impact of these effects on health outcomes.\n",
      "Variable: Results, Respuesta: The results of the study on placebo and nocebo effects emphasize the importance of measuring expectations and psychological factors in understanding the impact of placebos and nocebos on health outcomes.\n",
      "Variable: Conclusions, Respuesta: The conclusions of the study suggest that measuring expectations and psychological factors is crucial in understanding and harnessing the placebo and nocebo effects in healthcare settings.\n",
      "Variable: Clinical Relevance, Respuesta: The clinical relevance of measuring expectations and psychological factors in placebo and nocebo effects is significant as it can help healthcare providers better understand and harness the power of these effects in patient care. By recognizing and utilizing the impact of expectations on treatment outcomes, healthcare professionals can optimize therapeutic interventions and improve patient outcomes.\n",
      "Procesando fpsyg-09-01240.pdf...\n",
      "Variable: Title, Respuesta: \"Application of Bayes’ Theorem in Valuating Depression Tests Performance\"\n",
      "Variable: Authors, Respuesta: Marco Tommasi, Grazia Ferrara, and Aristide Saggino\n",
      "Variable: Publication Date, Respuesta: 23-07-2018\n",
      "Variable: Objective of the Study, Respuesta: The objective of the study is to apply Bayes' Theorem to evaluate the performance of depression tests in clinical psychology, with a focus on the validity of clinical diagnoses.\n",
      "Variable: Methodology Used, Respuesta: The methodology used in the study involved applying Bayes' Theorem to evaluate the performance of depression tests. This mathematical approach helps in assessing the accuracy and reliability of diagnostic tests for depression.\n",
      "Variable: Study Sample, Respuesta: The study sample in this research consists of individuals who were assessed using depression tests to evaluate the performance of these tests in diagnosing depression.\n",
      "Variable: Results, Respuesta: The results of the study on the application of Bayes' Theorem in evaluating depression tests performance indicated that the method showed promising results in improving the accuracy of clinical diagnoses of depression. The study emphasized the importance of using Bayesian statistics to enhance the validity of clinical diagnoses in psychology.\n",
      "Variable: Conclusions, Respuesta: The conclusions of the study on the application of Bayes' Theorem in evaluating depression tests performance suggest that incorporating Bayesian analysis can enhance the accuracy of diagnostic tests for depression, ultimately improving the validity of clinical diagnoses in clinical psychology.\n",
      "Variable: Clinical Relevance, Respuesta: The clinical relevance of applying Bayes' Theorem in evaluating depression tests performance lies in improving the accuracy of clinical diagnoses in psychology. By utilizing this mathematical tool, healthcare professionals can better assess the validity of diagnostic tests, leading to more precise identification and treatment of depression in patients. This can ultimately enhance patient care and outcomes in the field of clinical psychology.\n",
      "Procesando fpsyg-11-01354.pdf...\n",
      "Variable: Title, Respuesta: \"Putting the ‘Art’ Into the ‘Art of Medicine’: The Under-Explored Role of Artifacts in Placebo Studies\"\n",
      "Variable: Authors, Respuesta: Michael H. Bernstein, Cosima Locher, Tobias Kube, Sarah Buergler, Sif Stewart-Ferrer, and Charlotte Blease.\n",
      "Variable: Publication Date, Respuesta: 22-07-2020\n",
      "Variable: Objective of the Study, Respuesta: The objective of the study is to explore the role of artifacts in placebo studies and to emphasize the importance of considering artifacts in the context of the placebo effect in medicine.\n",
      "Variable: Methodology Used, Respuesta: The methodology used in the study involves a conceptual analysis focusing on the role of artifacts in placebo studies. The researchers explore how artifacts, such as pills, injections, or medical devices, contribute to the placebo effect in healthcare settings. They delve into the influence of these artifacts on patient outcomes and the overall effectiveness of medical treatments.\n",
      "Variable: Study Sample, Respuesta: The study sample in this research likely consists of individuals who participated in placebo studies exploring the role of artifacts in the placebo effect.\n",
      "Variable: Results, Respuesta: The results of the study emphasize the importance of artifacts in placebo studies and highlight the under-explored role of artifacts in the placebo effect. The authors suggest that artifacts, such as medical devices or symbols, play a significant role in shaping patients' expectations and responses to treatments, influencing the placebo effect in healthcare settings.\n",
      "Variable: Conclusions, Respuesta: The conclusions of the study emphasize the importance of considering artifacts, such as pills, in placebo studies and how they can influence patient outcomes and perceptions. The authors suggest that these artifacts play a significant role in the placebo effect and should be further explored in medical research.\n",
      "Variable: Clinical Relevance, Respuesta: The clinical relevance of the under-explored role of artifacts in placebo studies lies in understanding how external factors, such as the appearance and administration of medications, can influence patient outcomes. By recognizing the impact of these artifacts, healthcare providers can optimize treatment strategies and enhance patient care through improved placebo responses.\n",
      "Procesando fpsyg-12-639236.pdf...\n",
      "Variable: Title, Respuesta: \"Placebo Effects on Stress, but Not on Pain Reports\"\n",
      "Variable: Authors, Respuesta: Sara Magelssen Vambheim, Hojjat Daniali, Magne Arve Flaten\n",
      "Variable: Publication Date, Respuesta: 07-06-2021\n",
      "Variable: Objective of the Study, Respuesta: The objective of the study was to investigate the impact of placebo effects on stress and pain reports, specifically examining how contextual factors like participant/experimenter sex may influence these effects.\n",
      "Variable: Methodology Used, Respuesta: The methodology used in the study involved conducting multiple experiments to investigate the placebo effects on stress and pain reports. The researchers manipulated contextual factors such as participant/experimenter sex to examine their potential moderating effects on the placebo response. The study likely employed experimental designs, placebo administration, stress and pain assessments, and statistical analyses to draw conclusions about the impact of placebos on stress and pain perception.\n",
      "Variable: Study Sample, Respuesta: The study sample in this research consisted of participants recruited to take part in multiple experiments investigating the placebo effects on stress and pain reports. The participants were likely from the general population or specific groups recruited for the study.\n",
      "Variable: Results, Respuesta: The study found that placebo effects influenced stress reports but did not have a significant impact on pain reports across multiple experiments.\n",
      "Variable: Conclusions, Respuesta: The study concluded that placebo effects influenced stress reports but did not have a significant impact on pain reports.\n",
      "Variable: Clinical Relevance, Respuesta: The clinical relevance of the study on placebo effects on stress and pain reports suggests that contextual factors, such as participant/experimenter sex, may influence the effectiveness of placebos in managing stress but not pain. This highlights the importance of considering individual differences and contextual factors in the design and interpretation of placebo studies in healthcare settings.\n",
      "Procesando fpsyt-14-1301143.pdf...\n",
      "Variable: Title, Respuesta: \"Placebo stimulates neuroplasticity in depression: implications for clinical practice and research\"\n",
      "Variable: Authors, Respuesta: The authors of the study are Brian J. Mickey, Jeremy Seymour, Nigel Mathers, Naseem Akhtar Qureshi, and Peter S. Micalos.\n",
      "Variable: Publication Date, Respuesta: 10-01-2024\n",
      "Variable: Objective of the Study, Respuesta: The objective of the study is to explore how placebos can stimulate neuroplasticity in depression and to discuss the implications of this finding for clinical practice and research in the field of psychiatry.\n",
      "Variable: Methodology Used, Respuesta: The methodology used in the study involved a review of existing literature and research on the topic of placebo effects on neuroplasticity in depression. The authors likely analyzed and synthesized data from various studies to draw conclusions about the potential implications for clinical practice and research.\n",
      "Variable: Study Sample, Respuesta: The study sample in this research likely consisted of individuals with depression who were administered a placebo to investigate its effects on neuroplasticity.\n",
      "Variable: Results, Respuesta: The results of the study suggest that placebos can stimulate neuroplasticity in depression, which has implications for both clinical practice and research in the field.\n",
      "Variable: Conclusions, Respuesta: The conclusion of the study suggests that placebos may have a positive impact on neuroplasticity in depression, which has implications for both clinical practice and research in the field of psychiatry.\n",
      "Variable: Clinical Relevance, Respuesta: The clinical relevance of the study suggests that utilizing placebos in the treatment of depression may have a positive impact on neuroplasticity, which could have implications for improving treatment outcomes in clinical practice and guiding future research in this area.\n",
      "Tabla generada:\n",
      "               PDF Name                                              Title  \\\n",
      "0    fpsyg-08-00308.pdf  Placebo and Nocebo Effects: The Advantage of M...   \n",
      "1    fpsyg-09-01240.pdf  \"Application of Bayes’ Theorem in Valuating De...   \n",
      "2    fpsyg-11-01354.pdf  \"Putting the ‘Art’ Into the ‘Art of Medicine’:...   \n",
      "3   fpsyg-12-639236.pdf  \"Placebo Effects on Stress, but Not on Pain Re...   \n",
      "4  fpsyt-14-1301143.pdf  \"Placebo stimulates neuroplasticity in depress...   \n",
      "\n",
      "                                             Authors Publication Date  \\\n",
      "0                    Nicole Corsi and Luana Colloca.       06-03-2017   \n",
      "1  Marco Tommasi, Grazia Ferrara, and Aristide Sa...       23-07-2018   \n",
      "2  Michael H. Bernstein, Cosima Locher, Tobias Ku...       22-07-2020   \n",
      "3  Sara Magelssen Vambheim, Hojjat Daniali, Magne...       07-06-2021   \n",
      "4  The authors of the study are Brian J. Mickey, ...       10-01-2024   \n",
      "\n",
      "                              Objective of the Study  \\\n",
      "0  The objective of the study was to highlight th...   \n",
      "1  The objective of the study is to apply Bayes' ...   \n",
      "2  The objective of the study is to explore the r...   \n",
      "3  The objective of the study was to investigate ...   \n",
      "4  The objective of the study is to explore how p...   \n",
      "\n",
      "                                    Methodology Used  \\\n",
      "0  The methodology used in the study involved mea...   \n",
      "1  The methodology used in the study involved app...   \n",
      "2  The methodology used in the study involves a c...   \n",
      "3  The methodology used in the study involved con...   \n",
      "4  The methodology used in the study involved a r...   \n",
      "\n",
      "                                        Study Sample  \\\n",
      "0  The study sample in the research consisted of ...   \n",
      "1  The study sample in this research consists of ...   \n",
      "2  The study sample in this research likely consi...   \n",
      "3  The study sample in this research consisted of...   \n",
      "4  The study sample in this research likely consi...   \n",
      "\n",
      "                                             Results  \\\n",
      "0  The results of the study on placebo and nocebo...   \n",
      "1  The results of the study on the application of...   \n",
      "2  The results of the study emphasize the importa...   \n",
      "3  The study found that placebo effects influence...   \n",
      "4  The results of the study suggest that placebos...   \n",
      "\n",
      "                                         Conclusions  \\\n",
      "0  The conclusions of the study suggest that meas...   \n",
      "1  The conclusions of the study on the applicatio...   \n",
      "2  The conclusions of the study emphasize the imp...   \n",
      "3  The study concluded that placebo effects influ...   \n",
      "4  The conclusion of the study suggests that plac...   \n",
      "\n",
      "                                  Clinical Relevance  \n",
      "0  The clinical relevance of measuring expectatio...  \n",
      "1  The clinical relevance of applying Bayes' Theo...  \n",
      "2  The clinical relevance of the under-explored r...  \n",
      "3  The clinical relevance of the study on placebo...  \n",
      "4  The clinical relevance of the study suggests t...  \n",
      "Archivos generados:\n",
      "- extracted_pharmaceutical_data_2024-12-15_12-32.csv\n",
      "- extracted_pharmaceutical_data_2024-12-15_12-32.xlsx\n"
     ]
    }
   ],
   "source": [
    "import datetime  # Para manejar la fecha y hora\n",
    "\n",
    "# Obtener la fecha y hora actual en el formato deseado\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# Procesamos los PDFs y almacenamos los datos extraídos en una lista de diccionarios\n",
    "data = process_pdfs(pdf_paths)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generar nombres de archivos con la fecha y hora\n",
    "csv_filename = f\"extracted_pharmaceutical_data_{current_time}.csv\"\n",
    "excel_filename = f\"extracted_pharmaceutical_data_{current_time}.xlsx\"\n",
    "\n",
    "# Guarda la tabla en un archivo CSV y en un archivo Excel\n",
    "df.to_csv(csv_filename, index=False)\n",
    "df.to_excel(excel_filename, index=False)\n",
    "\n",
    "# Muestra la tabla generada\n",
    "print(\"Tabla generada:\")\n",
    "print(df)\n",
    "print(f\"Archivos generados:\\n- {csv_filename}\\n- {excel_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff83bf-1606-40a0-8ad4-2d94d95f4ce7",
   "metadata": {},
   "source": [
    "## **Conclusion of the Deliverable Development**\n",
    "\n",
    "The development of this project presented numerous challenges and learnings throughout its implementation. From processing PDFs to extracting information using language models like GPT-3.5-turbo, the approach evolved to address performance, organization, and optimization issues.\n",
    "\n",
    "### **Main Challenges Faced:**\n",
    "1. **Choice of LLM Model:**\n",
    "   - Initially, we tried to use models available on the Hugging Face API. However, the results did not meet expectations in terms of accuracy and availability, leading us to opt for the OpenAI API.\n",
    "\n",
    "2. **Compatibility and Versions:**\n",
    "   - The latest version of the OpenAI API presented initial issues, requiring a reconfiguration and the use of an older version (0.28). This ensured the functionality of the code but involved an adjustment in the implementation.\n",
    "\n",
    "3. **Token Limits:**\n",
    "   - During the first iterations, the queries to the models exceeded the token limits, generating errors and incomplete responses. To solve this, we split long texts into manageable fragments using the `split_text_into_chunks` function, optimizing the interaction with the API.\n",
    "\n",
    "4. **Lengthy and Redundant Responses:**\n",
    "   - The initial responses were too long and contained unnecessary introductions. The queries to the API were adjusted to make the responses more direct and relevant, especially for specific variables like title, authors, and publication date.\n",
    "\n",
    "5. **Organization of Results:**\n",
    "   - To avoid overwriting previous files and improve traceability, we implemented dynamic filenames with timestamps using the `datetime` module. This ensured that each script execution generated unique and easily identifiable results.\n",
    "\n",
    "### **Key Achievements:**\n",
    "- **Efficient PDF Processing:**\n",
    "   - We implemented a robust solution that allows extracting text from multiple PDFs and splitting it into fragments for efficient API queries.\n",
    "\n",
    "- **Query Optimization:**\n",
    "   - The queries were adapted to generate precise and brief responses, tailored to the specific needs of each variable of interest.\n",
    "\n",
    "- **Result Generation:**\n",
    "   - The results were structured in a clear and organized table, exported in CSV and Excel formats with dynamic names that facilitate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab3197-dbd8-4be5-b336-07a2d3ed00fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
